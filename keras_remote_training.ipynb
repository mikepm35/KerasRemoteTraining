{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Remote Training\n",
    "Uses a dataset of wine attributes to demonstrate a template for remote training with Keras. The talos module is used for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = {\n",
    "    'pip': False,                         # install packages in this notebook\n",
    "    'experiment_name': 'wine_quality_1',  # for talos scan\n",
    "    'run_scan': False,                    # whether to execute scan\n",
    "    'upload_results': False,              # upload results to S3 or use local file\n",
    "    'download_results': True,             # download results from S3 or use local file\n",
    "    's3bucket': 'keras-remote-training'   # can be None if using only local files\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filename = control['experiment_name'] + '.csv'\n",
    "deploy_filename = control['experiment_name'] + '.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if control['pip'] == False:\n",
    "    print('Skipping install of python packages')\n",
    "\n",
    "else:\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pwd\n",
    "from collections import OrderedDict\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib\n",
    "if pwd.getpwuid(os.getuid())[0] == 'kerasdeploy':\n",
    "    print('Using agg backend for matplotlib')\n",
    "    matplotlib.use(\"agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import talos as ta\n",
    "from talos import model as ta_model\n",
    "from talos.metrics.keras_metrics import precision, recall, f1score, matthews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tensorflow version: %s' % tf.VERSION)\n",
    "print('Keras version: %s' % keras.__version__)\n",
    "print('Talos version: %s' % ta.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation for data source:\n",
    "\n",
    "P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create normalized X numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prenorm_min = X.min(0)\n",
    "X_prenorm_ptp = X.ptp(0)\n",
    "X = (X - X_prenorm_min) / X_prenorm_ptp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Y numpy array with shape (observations, classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros((X.shape[0],2), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 7\n",
    "Y[:,0] = (df['quality'] < threshold)*1.0\n",
    "Y[:,1] = (df['quality'] >= threshold)*1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View balance of classes and calculate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_frac_lowq = np.sum(Y[:,0]) / Y.shape[0]\n",
    "Y_frac_highq = np.sum(Y[:,1]) / Y.shape[0]\n",
    "print('Fraction data of class low/high quality:\\n%f, %f' % (Y_frac_lowq, Y_frac_highq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_array = np.argmax(Y, axis=1)\n",
    "class_weights = compute_class_weight('balanced', np.unique(Y_array), Y_array)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print('Class weights:\\n%s' % class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model function compatible with talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x_train, y_train, x_val, y_val, params):\n",
    "    \"\"\"\n",
    "    Compiles and fits model using params as defined by talos.\n",
    "    Returns model_fit (history) object and model object.\n",
    "    \"\"\"\n",
    "        \n",
    "    model = keras.Sequential()\n",
    "        \n",
    "    ta_model.hidden_layers(model, params, 0)\n",
    "    \n",
    "    model.add(keras.layers.Dense(2, activation=params['last_activation'])) \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=params['optimizer'](lr=ta_model.normalizers.lr_normalizer(params['lr'],params['optimizer'])),\n",
    "        loss=params['losses'],\n",
    "        metrics=[\n",
    "            'acc',\n",
    "            precision, recall, f1score, matthews,\n",
    "            params['losses'],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model_fit = model.fit(\n",
    "        x=x_train, y=y_train, \n",
    "        epochs=params['epochs'], batch_size=params['batch_size'],\n",
    "        validation_data=(x_val, y_val),\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return model_fit, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameter space to explore for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_params = dict()\n",
    "ta_params['lr'] = [0.0005, 0.001, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5]\n",
    "ta_params['first_neuron'] = [4, 8, 16, 32]\n",
    "ta_params['hidden_layers'] = [0, 1, 2, 3]\n",
    "ta_params['batch_size'] = [2, 4, 16, 32]\n",
    "ta_params['epochs'] = [25, 50, 150]\n",
    "ta_params['dropout'] = (0, 0.5, 6)\n",
    "ta_params['shapes'] = ['brick', 'triangle']\n",
    "ta_params['optimizer'] = [keras.optimizers.Adam]\n",
    "ta_params['losses'] = ['categorical_crossentropy']\n",
    "ta_params['activation'] = ['relu']\n",
    "ta_params['last_activation'] = ['softmax']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if control['run_scan']:\n",
    "    ta_scan = ta.Scan(\n",
    "        x=X,\n",
    "        y=Y,\n",
    "        val_split=0.2,\n",
    "        seed=32,\n",
    "        model=get_model,\n",
    "        fraction_limit=0.25,\n",
    "        params=ta_params,\n",
    "        experiment_name=control['experiment_name'],\n",
    "        clear_session=True,\n",
    "        print_params=True\n",
    "    )\n",
    "    \n",
    "    ta.Deploy(ta_scan, control['experiment_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional upload of results to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if control['upload_results']:\n",
    "    print('Starting upload of results to S3...')\n",
    "    \n",
    "    boto3.client('s3').upload_file('./'+results_filename, control['s3bucket'], results_filename)\n",
    "    boto3.client('s3').upload_file('./'+deploy_filename, control['s3bucket'], deploy_filename) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional download of results from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if control['download_results']:\n",
    "    print('Starting download of results from S3...')\n",
    "    \n",
    "    boto3.client('s3').download_file(control['s3bucket'], results_filename, './'+results_filename)\n",
    "    boto3.client('s3').download_file(control['s3bucket'], deploy_filename, './'+deploy_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_restore = ta.Restore('./'+deploy_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('./'+results_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate AUC from the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ta_restore.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(np.argmax(Y, axis=-1), np.argmax(y_pred, axis=-1), output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(Y, y_pred, average='weighted')\n",
    "print('AUC score for best model: %f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize results distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"val_acc\", y=\"val_categorical_crossentropy\", data=df_results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"categorical_crossentropy\", y=\"val_categorical_crossentropy\", data=df_results);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add metric to track underfitting/overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['loss_diff'] = df_results['val_categorical_crossentropy'] - df_results['categorical_crossentropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_t = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"val_acc\", y=\"loss_diff\", data=df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show top results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_cols = [\n",
    "    'hidden_layers','activation','batch_size',\n",
    "    'first_neuron','lr','shapes','dropout','epochs'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results[df_results['loss_diff']<diff_t][param_cols+['acc','val_acc','matthews','val_matthews','loss_diff']].sort_values(by=['val_acc'], ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_melt = df_results[df_results['loss_diff']<diff_t].sort_values(by=['val_acc'], ascending=False).head(10)\n",
    "df_results_melt['index1'] = df_results_melt.index\n",
    "df_results_melt = pd.melt(df_results_melt, id_vars=['index1'], value_vars=['categorical_crossentropy', 'val_categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.barplot(x=\"index1\", y=\"value\", hue=\"variable\", data=df_results_melt)\n",
    "plt.legend(loc='lower center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create correlation matrix and show values against val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical columns\n",
    "df_results_cat = df_results[df_results['loss_diff']<diff_t]\n",
    "df_results_cat[\"shapes_cat\"] = df_results[\"shapes\"].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = df_results_cat[param_cols+['shapes_cat']+['val_acc','val_matthews','loss_diff']].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(150, 275, s=80, l=55, n=9, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr['val_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot performance over epochs and batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"epochs\", y=\"val_acc\", hue=\"batch_size\", kind=\"bar\", data=df_results_cat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"epochs\", y=\"loss_diff\", hue=\"batch_size\", kind=\"box\", data=df_results_cat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
